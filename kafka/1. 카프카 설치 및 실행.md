

### Apache Kafka

#### 다운로드

- 다운로드 버전 확인 

  - https://kafka.apache.org/downloads

- 다운로드

```bash
sudo wget http://apache.mirror.cdnetworks.com/kafka/2.6.0/kafka_2.13-2.6.0.tgz
```

#### Zookeeper

- 설정파일 위치
```bash
sudo vi ${ZOOKEEPER_HOME}/config/zookeeper.properties
```

- 설정파일 변경

```properties
# the directory where the snapshot is stored.
dataDir=/data/zookeeper
    
# the port at which the clients will connect
clientPort=2181
    
# disable the per-ip limit on the number of connections 
# since this is a non-production config
maxClientCnxns=0
    
## tickTime(ms) * initLimit(sec)
## tickTime(ms) * syncLimit(sec)
tickTime=2000
initLimit=5 # Follower가 Leader와 연결할 수 있는 최대 시간 (이 시간동안 리더와 연결을 못 하면 초기화에 실패 / 5sec * 2000ms = 10sec)
syncLimit=2 # Follower가 Leader와 연결할 수 있는 최대 시간 (이 시간 동안 리더와 연결을 못 하면 동기화 실패 / 2sec * 2000ms = 4sec)
    

# Pattern: server.${x}=${hostname}:{peerPort}:{leaderPort}
## ${x}: 서버의 ID, 임의의 정수
## ${hostname}: 서버의 호스트이름 or IP
## ${peerPort}: 클러스터 내에서 서버들이 서로 통신할 때 사용하는 TCP 포트
## ${leaderPort}: 리더 선출할 때 사용되는 TCP 포트
server.1=kafka-server1:2888:3888
server.2=kafka-server2:2888:3888
server.3=kafka-server3:2888:3888
```

- myid 파일 생성

  - 파일 생성 위치

    - `dataDir` 에 입력한 경로

```bash
echo 1 > /data/zookeeper/myid
```

  - `dataDir` 경로 변경

    - `/tmp` 경로 사용 금지
    - 운영체제에서 `/tmp` 디렉터리 clear 하는 기준
      - `debian` 계열
        - 리부팅 시 삭제
      - `linux` 계열 (centos 7 기준)
        - `/usr/lib/tmpfiles.d/tmp.conf` 에 정책이 있다.

#### Kafka

- 설정파일 위치

```bash
sudo vi ${ZOOKEEPER_HOME}/config/server.properties
```

- 설정파일 변경
```properties
# The id of the broker. This must be set to a unique integer for each broker.
broker.id=1
    
# The address the socket server listens on. It will get the value returned from
# java.net.InetAddress.getCanonicalHostName() if not configured.
# Pattern: ${protocol}:${hostname}:{port}, 쉼표 구분으로 여러개 사용 가능
listeners=PLAINTEXT://:9092
    
# Hostname and port the broker will advertise to producers and consumers.
advertised.listeners=PLAINTEXT://${127.0.0.1:9092}
    
# A comma separated list of directories under which to store log files
# 모든 메시지를 로그 세그먼트 단위로 묶어서 설정된 경로(디스크)에 저장한다.
log.dirs=/data/kafka-logs
    
# The minimum age of a log file to be eligible for deletion due to age
# 메시지 보존 기간 설정, 
log.retention.hours=72
    
# Zookeeper connection string.
# 연결할 주키퍼 접속정보
# Pattern: ${hostname}:${port}/${optional_directory}
# /${optional_directory}: 카프카 클러스터의 chroot 환경으로 사용될 주키퍼 경로, 지정하지 않으면 루트 디렉터리
# chroot 경로를 사용하는 것이 좋다고 함, 다른 클러스터와의 충돌없이 주키퍼 클러스터를 공유할 수 있음,
zookeeper.connect=${zookeeper1:port1},${zookeeper2:port2},${zookeeper3:port3}
    
############################# Broker config (추가 설정)  #############################
# Enables delete topic. Delete topic through the admin tool will have no effect if this config is turned off
delete.topic.enable=true
    
# Allow automatic topic creation on the broker when subscribing to or assigning a topic.
# A topic being subscribed to will be automatically created only if the broker allows for it using `auto.create.topics.enable` broker configuration.
# This configuration must be set to `false` when using brokers older than 0.11.0
allow.auto.create.topics=false
```

  - `broker.id`
  - `listeners`, `advertised.listeners` 설정
  - `log.dirs` 디렉터리 변경
    
    - `/tmp` 경로 사용 금지
  - `zookeeper.connect` 설정
  - `log.retention.hours` 변경



- 기타 브로커 옵션

| 옵션                         | 설명                                                         |
| ---------------------------- | ------------------------------------------------------------ |
| auto.create.topics.enable    | 토픽의 자동생성은,<br />- producer가 토픽에 메시지를 쓸 때<br />- consumer가 토픽으로부터 메시지를 읽기 시작할 때<br />- 클라이언트가 토픽에 대한 메타데이터를 요청할 때<br /><br />토픽을 명시적을 관리하는게 좋은경우 false로 설정하면 된다. (권장) |
| auto.leader.rebalance.enable | 모든 토픽의 리더 역할이 하나의 브로커에 집중되면 카프카 클러스터의 균형이 깨질 수 있다.<br />이 설정을 활성화 하면 리더 역할이 균등하게 분산되도록 해줌<br /><br />leader.imbalance.check.interval.seconds에 설정한 주기마다 백그라운드 스레드가 확인함<br />leader.imbalance.per.broker.percentage에 설정된 값을 넘어가면 리밸런싱 발생 |
|                              |                                                              |



- 기타 토픽 옵션

| 옵션                                                         | 설명                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| num.partitions                                               | 토픽이 자동생성될 때 정해지는 파티션 개수 (default: 1)       |
| default.replication.factor <br />(버전마다 옵션 명이 다른듯) | 토픽이 자동생서욀 때 정해지는 복제 팩터 개수 (default: 1)<br />min.insync.replicas 보다 최소한 1이상 잡아줄 것을 강력히 권장 |
| log.retention.ms<br />log.retention.minute<br />log.retention.hour | 메시지 보존해야하는 기간 설정, 3개중 1개 이상의 설정이 정의되면 작은 단위의 설정값이 우선순위가 높다. (ms > minute > hour) |
| log.retention.bytes                                          | 메시지 만료기준의 용량, 파티션 마다의 설정임                 |
| log.segment.bytes                                            | 설정된 값에 다다르면 기존 로그 세그먼트를 닫고 새로운 세그먼트를 연다.<br />로그 세그먼트는 닫히기 전까지는 만료와 삭제의 대상이 아니다.<br /><br />log.segment.bytes가 100M, log.retention.hour가 72, 100M가 차는데 평균 7일이 걸린다고 가정했을 때<br />- 7일동안 세그먼트가 열린 상태 + 로그 삭제 주기 72시간(3일) = 10일후 삭제가 된다. |
| min.insync.replicas                                          | 복제 할 갯수 (리더 1개, 팔로워중 N-1개), N개의 브로커로부터 응답을 받아야 쓰기 작업이 성공한다. |
| message.max.bytes                                            | 압축된 메시지의 크기를 기준으로, producer가 설정한 값보다 큰 메시지를 전송하는경우 에러를 리턴한다. <br /><br />해당 설정은 컨슈머 클라이언트의 fetch.message.max.bytes 설정과 일치해야하고, 클러스터 브로커의 replica.fetch.max.bytes 설정과도 일치해야한다.<br />(message.max.bytes > fetch.message.max.bytes 인 경우 컨슈머에서 읽기 작업이 멈추는 경우가 발생한다.) |

- log.retention.ms(minute/hour)와 log.retention.bytes가 둘 다 설정되면 둘 중 하나만 만족해도 지워짐, 시간 또는 용량기준으로 하나만 선택하길 권장



**KAFKA_HEAP_OPTS 설정**

- `cd ${KAFKA_HOME}/bin`

- `vi kafka-server-start.sh`

- ``` sh
  if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then
      export KAFKA_HEAP_OPTS="-Xmx8G -Xms8G"
  fi
  ```



#### Java 설정

- profile 위치

```bash
sudo vi /etc/profile
```

- profile 변경

```sh
export JAVA_HOME=/app/java/jdk1.8.0_271
export PATH=$PATH:$JAVA_HOME/bin
```



#### 구동

- `zookeeper`  시작

```sh
sudo ${KAFKA_HOME}/bin/zookeeper-server-start.sh -daemon ${KAFKA_HOME}/config/zookeeper.properties
```

- `kafka` 시작 

  ```sh
sudo ${KAFKA_HOME}/bin/kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties
  ```
- `kafka`  종료
```sh
sudo ${KAFKA_HOME}/bin/kafka-server-stop.sh
```
  - `zookeeper` 종료
```sh
sudo ${KAFKA_HOME}/bin/zookeeper-server-stop.sh
```
- sh 파일 이용

  - `zookeeper-run.sh`

```sh
#!/bin/bash
KAFKA_HOME=
      
case "$1" in
start)
sudo $KAFKA_HOME/bin/zookeeper-server-start.sh -daemon $KAFKA_HOME/config/zookeeper.properties
echo "zookeeper start"
;;
stop)
sudo $KAFKA_HOME/bin/zookeeper-server-stop.sh
echo "zookeeper stop"
;;
*)
echo "Usage: $0 {start|stop}"
exit 1
esac
exit 0
```

  

  - `kafka-run.sh`

```sh
#!/bin/bash
KAFKA_HOME=
      
case "$1" in
start)
sudo $KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties
echo "kafka start"
;;
stop)
sudo $KAFKA_HOME/bin/kafka-server-stop.sh
echo "kafka stop"
;;
*)
echo "Usage: $0 {start|stop}"
exit 1
esac
exit 0
```





### 카프카 매니저 (CMAK)

#### 다운로드

- 다운로드 버전 확인

  - https://github.com/yahoo/CMAK/releases

- 다운로드

```bash
sudo wget https://github.com/yahoo/kafka-manager/archive/3.0.0.5.tar.gz
```

```bash
sudo tar -zxvf 3.0.0.5.tar.gz
```

- 빌드

  - JDK 11 이상

```sh
…
    
setJavaHome() {
java_cmd="$1/bin/java"
setThisBuild javaHome "root.scala.Some(file("$1"))"
export JAVA_HOME="${JDK_11_HOME}"
export JDK_HOME="${JDK_11_HOME}"
export PATH="$JAVA_HOME/bin:$PATH"
}

…
```

  - `./sbt clean dist`

- output 파일

```bash
sudo unzip -d /app/ target/universal/CMAK-3.0.0.5.zip
sudo mv /app/ target/universal/cmak-3.0.0.5 /app/kafka_2.13-2.6.0/cmak-3.0.0.5
```

- zookeeper host 설정

  - sudo vi conf/application.conf

```sh
kafka-manager.zkhosts="${zookeeper1:port1},${zookeeper2:port2},${zookeeper3:port3}"
```

- 실행

```sh
nohup sudo $CMAK_HOME/bin/cmak -Dconfig.file=$CMAK_HOME/conf/application.conf -java-home $JAVA_11_HOME &
```